{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39cc12de",
   "metadata": {},
   "source": [
    "# Bechdel Analysis\n",
    "#### CS5850 Final Project\n",
    "\n",
    "Alex Thurston, Hailey Dennis, Tyler Kunz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205c5cc3",
   "metadata": {},
   "source": [
    "# Data Collection and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6223616d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from numpy import linalg,mean,dot\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e1ab4fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get five-thirty-eight bechdel data\n",
    "def get_five_thirty_eight_bechdel_data():\n",
    "    data = pd.read_csv(\"https://raw.githubusercontent.com/fivethirtyeight/data/master/bechdel/movies.csv\")\n",
    "    select_columns = data[['year', 'imdb', 'title', 'clean_test', 'binary', 'budget_2013$', 'domgross_2013$', 'intgross_2013$']]\n",
    "    return select_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "980556c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Print correlation and covariance matrices\n",
    "def print_corr_cov_matrices(data):\n",
    "    print(data.corr())\n",
    "    print(data.cov())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31f9c43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates: True if duplicates were found, False if all data is unique\n",
    "def check_duplicates(data):\n",
    "    if len(select_columns['imdb']) != len(select_columns['imdb'].unique()):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "16fa93bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column to dataframe\n",
    "def add_column(df, col_name, new_list):\n",
    "    df.insert(len(df.columns), str(col_name), new_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d15e71f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns percentage of women in given crew role (e.g. Producer, Director\n",
    "def get_perc_women_role(crew_response, job_type):\n",
    "    female_count = 0\n",
    "    job_count = 0\n",
    "    for person in crew_response['crew']:\n",
    "        if person['job'] == job_type:\n",
    "            job_count += 1\n",
    "            if person['gender'] == 1:\n",
    "                female_count += 1\n",
    "    if job_count == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return female_count / job_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1ea53f2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected err=KeyError('adult'), type(err)=<class 'KeyError'>\n",
      "Unexpected err=KeyError('adult'), type(err)=<class 'KeyError'>\n",
      "Unexpected err=KeyError('adult'), type(err)=<class 'KeyError'>\n",
      "Unexpected err=KeyError('adult'), type(err)=<class 'KeyError'>\n",
      "Unexpected err=KeyError('adult'), type(err)=<class 'KeyError'>\n",
      "Unexpected err=KeyError('adult'), type(err)=<class 'KeyError'>\n"
     ]
    }
   ],
   "source": [
    "# Populate data\n",
    "data_file_name = \"bechdel_analysis_data.csv\"\n",
    "data_file_path = \"./bechdel_analysis_data.csv\"\n",
    "\n",
    "# See if data has already been populated in the current directory\n",
    "if os.path.isfile(data_file_path):\n",
    "    select_columns = pd.read_csv(data_file_path)\n",
    "else:\n",
    "    select_columns = get_five_thirty_eight_bechdel_data()\n",
    "    \n",
    "    #Gather TMDB data - setup\n",
    "    tmdb_api_key = \"55d7071c3daf17bcf8cc0f4a6f688a24\"\n",
    "    movie_ids = select_columns['imdb']\n",
    "\n",
    "\n",
    "    # Initialize empty arrays\n",
    "    adult = [None] * len(movie_ids)\n",
    "    genres = [None] * len(movie_ids)\n",
    "    prod_comps = [None] * len(movie_ids)\n",
    "    overview = [None] * len(movie_ids)\n",
    "    perc_women_producers = [None] * len(movie_ids)\n",
    "    perc_women_directors = [None] * len(movie_ids)\n",
    "\n",
    "    # Query the API for data\n",
    "    for i in range(len(movie_ids)):\n",
    "        try:\n",
    "            response = requests.get(\"https://api.themoviedb.org/3/movie/\" + str(movie_ids[i]) + \"?api_key=\" + str(tmdb_api_key) + \"&language=en-US\").json()\n",
    "            crew_response = requests.get(\"https://api.themoviedb.org/3/movie/\" + str(movie_ids[i]) + \"/credits?api_key=\" + str(tmdb_api_key) + \"&language=en-US\").json()\n",
    "            adult[i] = response['adult']\n",
    "            genres[i] = ','.join([ genre['name'] for genre in response['genres']])\n",
    "            prod_comps[i] = ','.join([company['name'] for company in response['production_companies']])\n",
    "            overview[i] = response['overview']\n",
    "            perc_women_producers[i] = get_perc_women_role(crew_response, 'Producer')\n",
    "            perc_women_directors[i] = get_perc_women_role(crew_response, 'Director')\n",
    "\n",
    "        except Exception as err:\n",
    "            print(f\"Unexpected {err=}, {type(err)=}\")\n",
    "            continue\n",
    "\n",
    "    # Add desired columns to select_columns\n",
    "    desired_cols = {'adult': adult, 'genres': genres, 'prod_comps': prod_comps, 'overview': overview,\n",
    "                    'perc_women_producers': perc_women_producers, \n",
    "                    'perc_women_directors': perc_women_directors}\n",
    "    for key in desired_cols.keys():\n",
    "        select_columns = add_column(select_columns, key, desired_cols[key])\n",
    "\n",
    "    #Save to csv so we don't have to requery the API every time\n",
    "    select_columns.to_csv(data_file_name, encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c293a2fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for null values: return columns and sums of null values located in each\n",
    "def null_values_in_columns(data):\n",
    "    null_cols = data.isnull().any()\n",
    "    return [data.columns[i] for i in range(len(data.columns)) if null_cols[i] == True]\n",
    "\n",
    "cols_with_nulls = null_values_in_columns(select_columns)\n",
    "print(cols_with_nulls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341ad046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutative function to remove rows with nulls\n",
    "def get_non_null_rows(df, col_with_nulls):\n",
    "    df = df[df[col_with_nulls].isnull() == False]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42483121",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in cols_with_nulls:\n",
    "    select_columns = get_non_null_rows(select_columns, i)\n",
    "    \n",
    "select_columns.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4983e966",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(\"Null values in columns\")\n",
    "print(null_values_in_columns(select_columns))\n",
    "print()\n",
    "print(\"Null counts\")\n",
    "print(select_columns.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd56457b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import preprocessor as pre\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7a9162",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    no_escape = re.sub(r'&.+?;', '', text)\n",
    "    no_punc = \"\".join([i for i in no_escape if i not in string.punctuation])\n",
    "    lower_text = no_punc.lower()\n",
    "    return lower_text\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e451f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean text for later use\n",
    "select_columns['title'] = select_columns['title'].apply(clean_text)\n",
    "select_columns['overview'] = select_columns['overview'].apply(clean_text)\n",
    "select_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff9a9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "select_columns.to_csv(\"bechdel_analysis_data_cleaned.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4bba0e",
   "metadata": {},
   "source": [
    "# Data Preprocessing / Feature Selection\n",
    "Determining correlation and variance among and between features, summarizing, and looking at individual correlation with Bechdel test results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c0212",
   "metadata": {},
   "outputs": [],
   "source": [
    "def currency_conversion(amt):\n",
    "    return \"${:,.2f}\".format(amt)\n",
    "\n",
    "# Modes = 'overall', 'passing', 'failing' -- make sure you pass in data that corresponds to the mode!\n",
    "def quick_metrics(column_name, xdata, mode, currency=False):\n",
    "    if currency:\n",
    "        print(f\"{column_name} min {mode}:\", currency_conversion(xdata.min()))\n",
    "        print(f\"{column_name} max {mode}:\", currency_conversion(xdata.max()))\n",
    "        print(f\"{column_name} mean {mode}:\", currency_conversion(xdata.mean()))\n",
    "        print(f\"{column_name} standard deviation {mode}:\", currency_conversion(xdata.std()))\n",
    "    else:\n",
    "        print(f\"{column_name} min {mode}:\", xdata.min())\n",
    "        print(f\"{column_name} max {mode}:\", xdata.max())\n",
    "        print(f\"{column_name} mean {mode}:\", xdata.mean())\n",
    "        print(f\"{column_name} standard deviation {mode}:\", xdata.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d738072c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"bechdel_analysis_data_cleaned.csv\", float_precision=None)\n",
    "data = data.dropna()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7617527f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9de5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.cov()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "316bb090",
   "metadata": {},
   "source": [
    "Convert the pass/fail string binary column to 1=pass and 0=fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ed54c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pass_fail_data = pd.get_dummies(data.binary, prefix='binary')\n",
    "pass_fail_data = pass_fail_data.drop(\"binary_FAIL\", axis=1)\n",
    "data = data.drop(columns=['binary'])\n",
    "data.insert(5, \"binary_PASS\", pass_fail_data[\"binary_PASS\"])\n",
    "data_new = data\n",
    "data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f8a943",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d812792e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new.mad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82be24f9",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Low positive correlation between year and passing\n",
    "- Low negative correlation between all monetary categories and passing\n",
    "- Fairly high correlations between all monetary categories with each other\n",
    "- Percentage of women directors had the largest correlation (positive) with passing at .2\n",
    "- High correlation between domgross_2013 and int_gross2013\n",
    " - We will opt to remove int_gross2013 as it has a significantly lower mean absolute deviation\n",
    " - We will keep budget_2013 as it stil offers significant variability\n",
    "- Adult needs to be removed\n",
    "\n",
    "### Domestic Gross Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf2d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_fail = data_new.loc[data_new[\"binary_PASS\"] == 0] \n",
    "data_pass = data_new.loc[data_new[\"binary_PASS\"] == 1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bc7aa0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quick_metrics('domgross_2013$', data_new['domgross_2013$'], 'overall', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "593835c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_metrics('domgross_2013$', data_pass['domgross_2013$'], 'passing', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bd4f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_metrics('domgross_2013$', data_fail['domgross_2013$'], 'failing', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fa93fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(data_new[\"binary_PASS\"], data_new[\"domgross_2013$\"])\n",
    "plt.title(\"Passing Movies versus Domestic Gross Sales\")\n",
    "plt.xlabel(\"Binary_PASS: 0 - Failed, 1 - Passed\")\n",
    "plt.ylabel(\"Domestic Gross Sales ($100 million)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3760c4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.bar([\"Pass\", \"Fail\"], [data_pass[\"domgross_2013$\"].mean(), data_fail[\"domgross_2013$\"].mean()])\n",
    "plt.title(\"Bechdel Test Result vs. Average Domestic Gross\")\n",
    "plt.xlabel(\"Bechdel Test Result\")\n",
    "plt.ylabel(\"2013 Average Domestic Gross ($100 million)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590d2ce1",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- There is a clear correlation between 2013 average domestic gross and Bechdel Test result\n",
    "- Lower domestic gross sales means higher likelihood to pass the Bechdel test\n",
    "\n",
    "\n",
    "### Budget Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc8687d",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_metrics('budget_2013$', data_new['budget_2013$'], 'overall', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b48de73f",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_metrics('budget_2013$', data_pass['budget_2013$'], 'passing', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e18b43",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "quick_metrics('budget_2013$', data_fail['budget_2013$'], 'failing', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b9e7a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(data_new[\"binary_PASS\"], data_new[\"budget_2013$\"])\n",
    "plt.title(\"Passing Movies versus Budget\")\n",
    "plt.xlabel(\"Binary_PASS: 0 - Failed, 1 - Passed\")\n",
    "plt.ylabel(\"Budget ($100 million)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ce8db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([\"Pass\", \"Fail\"], [data_pass[\"domgross_2013$\"].mean(), data_fail[\"domgross_2013$\"].mean()])\n",
    "plt.title(\"Bechdel Test Result vs. Average Budget\")\n",
    "plt.xlabel(\"Bechdel Test Result\")\n",
    "plt.ylabel(\"Average Budget ($100 million)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c48093",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "- Similar observations to the domestic gross sales\n",
    "- Movies that fail the Bechdel test have a higher average budget\n",
    "\n",
    "### Genre Analysis\n",
    "We use one-hot-encoding to represent genres as they have useful predictive power. We will not be doing this for production companies as they don't have as much predictive power and there are significantly more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2e196",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_new[\"genres\"] = data_new[\"genres\"].str.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321871a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "genre_data = pd.DataFrame(mlb.fit_transform(data_new[\"genres\"]),\n",
    "                          columns=mlb.classes_,\n",
    "                          index=data_new.index)\n",
    "genre_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac474c1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main_data_genre_data_combined = pd.concat([data_new.reset_index(drop=True),genre_data.reset_index(drop=True)], axis=1)\n",
    "main_data_genre_data_combined = main_data_genre_data_combined.drop(['genres'], axis=1)\n",
    "main_data_genre_data_combined.to_csv(\"bechdel_analysis_data_cleaned_with_genres.csv\")\n",
    "main_data_genre_data_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7646b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_data.to_csv(\"genre_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfafaab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Genre by Movie Count\")\n",
    "genre_data.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4b3b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_fail_genre = pd.concat([pass_fail_data, genre_data], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c0eeb51",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Correlation between genre and test results\")\n",
    "pass_fail_genre_corr = pass_fail_genre.corr()\n",
    "pass_fail_genre_corr[[\"binary_PASS\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52018ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Covariance between genre and test results\")\n",
    "pass_fail_genre_cov = pass_fail_genre.cov()\n",
    "pass_fail_genre_cov[[\"binary_PASS\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9b3af98",
   "metadata": {},
   "source": [
    "- Genres with a clear positive correlation above 0.1 include romance and horror\n",
    "- Genres with a clear negative correlation above 0.1 include action, adventure, and crime\n",
    "\n",
    "### Year Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ae4422",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_data = data_new[['binary_PASS','year']].groupby('year').count()\n",
    "plt.plot(year_data.index,year_data['binary_PASS'])\n",
    "plt.title(\"Movies Per Year In Database\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7bb067",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPass rate by year\")\n",
    "year_pass_data = data_new[data_new[\"binary_PASS\"] == 1]\n",
    "year_pass_data = year_pass_data[['binary_PASS','year']].groupby('year').count()\n",
    "pass_percentage_data = year_pass_data / year_data\n",
    "pass_percentage_data = pass_percentage_data.fillna(0)\n",
    "pass_percentage_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86098ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(pass_percentage_data.index,pass_percentage_data['binary_PASS'])\n",
    "plt.title(\"Proportion of Movies Passing the Bechdel Test by Year\")\n",
    "plt.ylabel(\"Pass Proportion\")\n",
    "plt.xlabel(\"Year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cbda97",
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_percentage_post94 = pass_percentage_data[pass_percentage_data.index >= 1994].mean()\n",
    "pass_percentage_pre94 = pass_percentage_data[pass_percentage_data.index < 1994].mean()\n",
    "\n",
    "\n",
    "print(\"Average pass rate for movies prior to 1994:\\n\", pass_percentage_pre94)\n",
    "print(\"Average pass rate for movies 1994 and later:\\n\", pass_percentage_post94)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2b6a53",
   "metadata": {},
   "source": [
    "- Pass rate fluctuated greatly by year in early years, likely because of the smaller sample size\n",
    "- Rates seem to be stabilizing around .4 to .5 over time\n",
    "- Average pass rate slowly increases over time\n",
    "- Number of movies per year spiked following 1994-ish\n",
    "- Majority of our data averages near a 40-50% pass rate, but is lower prior to 1994 (less values)\n",
    "\n",
    "### Adult Movie Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8999f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adult_data = pd.get_dummies(data.adult, prefix='adult')\n",
    "adult_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5022064",
   "metadata": {},
   "source": [
    "No adult movies in the dataset.\n",
    "\n",
    "### Production Company Analysis\n",
    "\n",
    "We cover this in the Data Storage section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0631ce07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_new[\"prod_comps\"] = data_new[\"prod_comps\"].str.split(',')\n",
    "data_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea40123d",
   "metadata": {},
   "source": [
    "### Percentage of Women Producers Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6a1ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of movies with no women producers\n",
    "no_women = data_new.loc[data_new['perc_women_producers'] == 0]\n",
    "no_women.shape[0] / data_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac73c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_metrics(\"perc_women_producers\", data_new['perc_women_producers'], 'overall', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7895e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_metrics(\"perc_women_producers\", data_pass['perc_women_producers'], 'passing', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4a49ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_metrics(\"perc_women_producers\", data_fail['perc_women_producers'], 'failing', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98d23e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_percs = data_new['perc_women_producers'].unique()\n",
    "p_percs.sort()\n",
    "\n",
    "pass_p_percs = []\n",
    "\n",
    "for p in p_percs:\n",
    "    rows = data_new.loc[data_new['perc_women_producers'] == p]\n",
    "    passed = rows.loc[data_new['binary_PASS'] == 1]\n",
    "    pass_p_percs.append(passed.shape[0] / rows.shape[0])\n",
    "    \n",
    "plt.plot(p_percs, pass_p_percs)\n",
    "plt.title(\"Pass rates by Percentage of Producers\")\n",
    "plt.xlabel(\"Percentage of Women Producers\")\n",
    "plt.ylabel(\"Percentage Passing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04fb134",
   "metadata": {},
   "source": [
    "### Percentage of Women Directors Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "616cab1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Percentage of movies with no women directors\n",
    "no_women = data_new.loc[data_new['perc_women_directors'] == 0]\n",
    "no_women.shape[0] / data_new.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c055bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_metrics(\"perc_women_directors\", data_new['perc_women_directors'], 'overall', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50ecbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_metrics(\"perc_women_directors\", data_pass['perc_women_directors'], 'passing', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617ea851",
   "metadata": {},
   "outputs": [],
   "source": [
    "quick_metrics(\"perc_women_directors\", data_fail['perc_women_directors'], 'failing', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca9b2d6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d_percs = data_new['perc_women_directors'].unique()\n",
    "# d_percs = d_percs[1:]\n",
    "d_percs.sort()\n",
    "\n",
    "pass_d_percs = []\n",
    "\n",
    "for p in d_percs:\n",
    "    rows = data_new.loc[data_new['perc_women_directors'] == p]\n",
    "    passed = rows.loc[data_new['binary_PASS'] == 1]\n",
    "    pass_d_percs.append(passed.shape[0] / rows.shape[0])\n",
    "    \n",
    "plt.plot(d_percs, pass_d_percs)\n",
    "plt.title(\"Pass rates by Percentage of Women Directors\")\n",
    "plt.xlabel(\"Percentage of Women Directors\")\n",
    "plt.ylabel(\"Percentage Passing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52c3e53",
   "metadata": {},
   "source": [
    "### Observations on Crew Gender\n",
    "\n",
    "- Having women in director roles is much more indicative of a passed test than in producer roles\n",
    "- It is important to note that most of the movies have no women in these roles, so the majority of the data sits at 0%\n",
    "- The mean percentage of women in production roles overall is 16.15%\n",
    "- The mean percentage of women in director roles overall is 7.1%\n",
    "- Graphs are limited by differences in movie count per percentage\n",
    "- Regardless, having women in producer and director roles leads to a higher average pass rate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a338a7e1",
   "metadata": {},
   "source": [
    "### Test Passing Binary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2bad3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar([\"Pass\", \"Fail\"], [data_pass.shape[0], data_fail.shape[0]])\n",
    "plt.title(\"Overall Movie Count by Test Result\")\n",
    "plt.xlabel(\"Test Result\")\n",
    "plt.ylabel(\"Movie Count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be249704",
   "metadata": {},
   "source": [
    "We have more failing movies than passing in our dataset overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c0401d",
   "metadata": {},
   "source": [
    "### Principal Component Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9fb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_data = data_new[[\"year\", \"binary_PASS\",\"budget_2013$\",\"domgross_2013$\"]]\n",
    "pca_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab5cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "numComponents = 2\n",
    "cov = pca_data.cov().to_numpy()\n",
    "A = pca_data.to_numpy()\n",
    "[eigvals, pcs] = linalg.eig(cov)\n",
    "\n",
    "sorted_index = np.argsort(eigvals)[::-1]\n",
    "eigvals = eigvals[sorted_index]\n",
    "pcs = pcs[:,sorted_index]\n",
    "\n",
    "print(eigvals)\n",
    "M = (A-mean(A.T,axis=1)).T\n",
    "projected = dot(pcs.T,M).T\n",
    "projected = DataFrame(projected[:,:numComponents],columns=['pc1','pc2'])\n",
    "projected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed76a5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "projected.plot(kind='scatter',x='pc1',y='pc2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a750754f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "data_rescaled = scaler.fit_transform(pca_data.to_numpy())\n",
    "data_rescaled.shape\n",
    "\n",
    "\n",
    "pca = PCA().fit(data_rescaled)\n",
    "\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "xi = np.arange(1, 5, step=1)\n",
    "y = np.cumsum(pca.explained_variance_ratio_)\n",
    "\n",
    "plt.ylim(0.0,1.1)\n",
    "plt.plot(xi, y, marker='o', linestyle='--', color='b')\n",
    "\n",
    "plt.xlabel('Number of Components')\n",
    "plt.xticks(np.arange(0, 5, step=1)) #change from 0-based array index to 1-based human-readable label\n",
    "plt.ylabel('Cumulative variance (%)')\n",
    "plt.title('The number of components needed to explain variance')\n",
    "\n",
    "plt.axhline(y=0.95, color='r', linestyle='-')\n",
    "plt.text(0.5, 0.85, '95% cut-off threshold', color = 'red', fontsize=16)\n",
    "\n",
    "ax.grid(axis='x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "766e56b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pcs[:,:numComponents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fffc46b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pandas import Series\n",
    "\n",
    "fig,axes = plt.subplots(2,1,sharex=True)\n",
    "attrib = list(pca_data)         # get attribute names\n",
    "pcdata  = Series(pcs[:,0], index=attrib)\n",
    "pcdata.plot(kind='barh',ax=axes[0],color='k',alpha=0.7)\n",
    "axes[0].set_title(r'1st PC', size = 'x-large')\n",
    "pcdata  = Series(pcs[:,1], index=attrib)\n",
    "pcdata.plot(kind='barh',ax=axes[1],color='k',alpha=0.7)\n",
    "axes[1].set_title(r'2nd PC', size = 'x-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7b6ff7",
   "metadata": {},
   "source": [
    "Observations:\n",
    "- Our PCA results show a best combination of the domestic gross sales and budget.\n",
    "- We feel that we gain better comprehension by separating these, and will opt not to use the PCs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9a88c6",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "- We will remove the adult column as all values are false.\n",
    "- We will change the representation of our classification column (binary test pass/fail to 0 or 1)\n",
    "- We will remove intgross_2013 as it correlates highly with domgross_2013 but has a lower mean absolute deviation.\n",
    "- The rest of our dataset has highly variable features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1206b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['adult'], axis=1)\n",
    "data = data.drop(['intgross_2013$'], axis=1)\n",
    "data.to_csv(\"bechdel_analysis_data_cleaned.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4caed",
   "metadata": {},
   "source": [
    "# Data Storage / SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc65688",
   "metadata": {},
   "source": [
    "In the context of this project, we are using MySQL to perform queries for further data summarization and visualization. Our dataset is small enough that we feel comfortable keeping it in CSV form for other analytics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d97c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from mysql.connector import errorcode\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69e1f1d",
   "metadata": {},
   "source": [
    "### Database Setup\n",
    "This portion populates a MySQL server with values from a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "819b8ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this the first time\n",
    "# !pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea8ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure to your own user and password\n",
    "mysql_user = 'root'\n",
    "mysql_pw = ''\n",
    "mysql_host = 'localhost'\n",
    "\n",
    "engine = sqlalchemy.create_engine(f\"mysql+pymysql://{mysql_user}:{mysql_pw}@{mysql_host}\")\n",
    "conn = engine.connect()\n",
    "conn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448625c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"bechdel_analysis_data_cleaned.csv\", float_precision=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b3514c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_dml(dml_string):\n",
    "    try:\n",
    "        conn.execute(dml_string)\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Error:\", err)\n",
    "        \n",
    "def execute_query(query_string):\n",
    "    try:\n",
    "        res = conn.execute(query_string)\n",
    "        return res.fetchall()\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Error:\", err)\n",
    "\n",
    "def create_db():\n",
    "    drop_existing_db = \"DROP DATABASE IF EXISTS bechdel;\"\n",
    "    create_bechdel = \"CREATE DATABASE bechdel;\"\n",
    "    use_bechdel = \"USE bechdel;\"\n",
    "    try:\n",
    "        execute_dml(drop_existing_db)\n",
    "        execute_dml(create_bechdel)\n",
    "        execute_dml(use_bechdel)\n",
    "    except mysql.connector.Error as err:\n",
    "        print(\"Error:\", err)\n",
    "        \n",
    "def populate_db():\n",
    "    general_data = data.drop(['genres', 'prod_comps'], axis=1)\n",
    "    general_data.to_sql('general', conn, if_exists='replace', dtype={\n",
    "        'year': sqlalchemy.types.INTEGER(),\n",
    "        'imdb': sqlalchemy.types.VARCHAR(length=12),\n",
    "        'title': sqlalchemy.types.VARCHAR(length=255),\n",
    "        'clean_test': sqlalchemy.types.VARCHAR(length=20),\n",
    "        'binary_passed': sqlalchemy.types.INTEGER(),\n",
    "        'budget_2013$': sqlalchemy.types.BIGINT(),\n",
    "        'domgross_2013$': sqlalchemy.types.BIGINT(),\n",
    "        'intgross_2013$': sqlalchemy.types.BIGINT(),\n",
    "        'overview': sqlalchemy.types.TEXT(),\n",
    "        'perc_women_producers': sqlalchemy.types.FLOAT(),\n",
    "        'perc_women_directors': sqlalchemy.types.FLOAT()\n",
    "    })\n",
    "    \n",
    "    # Convert into workable list type before using .explode()\n",
    "    genre_data = data[['imdb', 'genres']]\n",
    "    for i in range(genre_data.count()[0]):\n",
    "        genre_data.iloc[i].genres = genre_data.iloc[i].genres.strip('[]').replace('\\'', \"\").split(', ')\n",
    "    genre_data = genre_data.explode('genres')\n",
    "    genre_data.to_sql('genre', conn, if_exists='replace', dtype={\n",
    "        'imdb': sqlalchemy.types.VARCHAR(length=12),\n",
    "        'genre': sqlalchemy.types.VARCHAR(length=20)\n",
    "    })\n",
    "    \n",
    "    prod_data = data[['imdb', 'prod_comps']]\n",
    "    for i in range(prod_data.count()[0]):\n",
    "        prod_data.iloc[i].prod_comps = prod_data.iloc[i].prod_comps.strip('[]').replace('\\'', \"\").split(', ')\n",
    "    prod_data = prod_data.explode('prod_comps')\n",
    "    prod_data.to_sql('production_company', conn, if_exists='replace', dtype={\n",
    "        'imdb': sqlalchemy.types.VARCHAR(length=12),\n",
    "        'genre': sqlalchemy.types.VARCHAR(length=50)\n",
    "    })\n",
    "    execute_dml('ALTER TABLE general ADD PRIMARY KEY (imdb);')\n",
    "    execute_dml('ALTER TABLE genre ADD FOREIGN KEY (imdb) REFERENCES general(imdb);')\n",
    "    execute_dml('ALTER TABLE production_company ADD FOREIGN KEY (imdb) REFERENCES general(imdb);')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63e67e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_db()\n",
    "populate_db()\n",
    "\n",
    "print(execute_query(\"DESC general\"), '\\n');\n",
    "print(execute_query(\"DESC genre\"), '\\n');\n",
    "print(execute_query(\"DESC production_company\"));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b027d0",
   "metadata": {},
   "source": [
    "### Querying the Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc91f70",
   "metadata": {},
   "source": [
    "#### Overall Financial Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c4e32fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Avg budget, domestic gross sales, and internationaly gross sales for movies that passed')\n",
    "\n",
    "res = execute_query(\"\"\"\n",
    "    SELECT CONCAT('$', FORMAT(avg(budget_2013$), 2)),\n",
    "           CONCAT('$', FORMAT(avg(domgross_2013$), 2))\n",
    "        FROM general\n",
    "    WHERE binary_PASS = 1;\n",
    "\"\"\"\n",
    ")\n",
    "print(res[0])\n",
    "\n",
    "print('\\nAvg budget, domestic gross sales, and internationaly gross sales for movies that failed')\n",
    "res = execute_query(\"\"\"\n",
    "    SELECT CONCAT('$', FORMAT(avg(budget_2013$), 2)),\n",
    "           CONCAT('$', FORMAT(avg(domgross_2013$), 2))\n",
    "        FROM general\n",
    "    WHERE binary_PASS = 0;\n",
    "\"\"\"\n",
    ")\n",
    "print(res[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed07795",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = execute_query(\"\"\"\n",
    "    SELECT title,\n",
    "           domgross_2013$,\n",
    "           binary_PASS\n",
    "    FROM general g\n",
    "    ORDER BY domgross_2013$ DESC\n",
    "    LIMIT 50;\n",
    "\"\"\")\n",
    "highest_sales = pd.DataFrame(res)\n",
    "print(\"\\nResults for 50 highest selling movies in the dataset\")\n",
    "highest_sales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23777132",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = execute_query(\"\"\"\n",
    "    SELECT title,\n",
    "           budget_2013$,\n",
    "           binary_PASS\n",
    "    FROM general g\n",
    "    ORDER BY budget_2013$ DESC\n",
    "    LIMIT 50;\n",
    "\"\"\")\n",
    "highest_budget = pd.DataFrame(res)\n",
    "print(\"\\nResults for 50 highest budget movies in the dataset\")\n",
    "highest_budget"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a215b980",
   "metadata": {},
   "source": [
    "#### Production Company Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f059d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = execute_query(\"\"\"\n",
    "    SELECT COUNT(*) AS movie_count,\n",
    "           prod_comps,\n",
    "           SUM(CASE WHEN g.binary_PASS = 1 THEN 1 ELSE 0 END) / COUNT(*) AS perc_passing\n",
    "    FROM production_company pc\n",
    "    JOIN general g ON pc.imdb = g.imdb\n",
    "    GROUP BY prod_comps\n",
    "    ORDER BY movie_count DESC\n",
    "    LIMIT 100;\n",
    "\"\"\")\n",
    "prod_passing = pd.DataFrame(res)\n",
    "print(\"\\nPassing percentages for most popular production companies in dataset\\n\")\n",
    "prod_passing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e8ef5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.plot(prod_passing.movie_count, prod_passing.perc_passing)\n",
    "plt.title(\"Passing Percentage by Production Company Movie Count\")\n",
    "plt.xlabel(\"Movies Produced by Company\")\n",
    "plt.ylabel(\"Percent of Movies Passing Bechdel Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24534a31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = execute_query(\"\"\"\n",
    "    SELECT COUNT(*) AS movie_count,\n",
    "           prod_comps,\n",
    "           SUM(CASE WHEN g.binary_PASS = 1 THEN 1 ELSE 0 END) / COUNT(*) AS perc_passing\n",
    "    FROM production_company pc\n",
    "    JOIN general g ON pc.imdb = g.imdb\n",
    "    GROUP BY prod_comps\n",
    "    HAVING perc_passing = 1\n",
    "    ORDER BY movie_count DESC;\n",
    "\"\"\")\n",
    "prod_passing = pd.DataFrame(res)\n",
    "print(\"Production companies with 100% pass rate, by movie count\\n\")\n",
    "prod_passing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a52e79",
   "metadata": {},
   "source": [
    "#### Genre Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f54c31",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = execute_query(\"\"\"\n",
    "    SELECT COUNT(*) AS movie_count,\n",
    "           genres,\n",
    "           SUM(CASE WHEN g.binary_PASS = 1 THEN 1 ELSE 0 END) / COUNT(*) AS perc_passing\n",
    "    FROM genre gn\n",
    "    JOIN general g ON gn.imdb = g.imdb\n",
    "    GROUP BY genres\n",
    "    ORDER BY movie_count DESC;\n",
    "\"\"\")\n",
    "genre_passing = pd.DataFrame(res)\n",
    "print(\"Passing percentages by genre\\n\")\n",
    "genre_passing.sort_values(by=['perc_passing'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b5ae58",
   "metadata": {},
   "source": [
    "#### Clean_test Analysis\n",
    "Note that only values of 'ok' indicate a pass in the binary_PASS column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10838741",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "res = execute_query(\"\"\"\n",
    "    SELECT COUNT(*) AS movie_count,\n",
    "           clean_test\n",
    "    FROM general g\n",
    "    GROUP BY clean_test\n",
    "    ORDER BY movie_count DESC;\n",
    "\"\"\")\n",
    "clean_test_freq = pd.DataFrame(res)\n",
    "print(\"Frequencies for clean_test classifications\\n\")\n",
    "clean_test_freq.sort_values(by=['movie_count'], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d34487",
   "metadata": {},
   "source": [
    "### Overall Observations\n",
    "* The average budget and sales are higher for movies that fail the Bechdel test.\n",
    "* The majority of movies in the top 50 for highest budget and sales fail the Bechdel test.\n",
    "* The most popular production companies in our data set (by movie count) mostly have passing percentages under 50%.\n",
    "* Production companies with 100% pass rate have a maximum of 6 movies in our data set.\n",
    "* As you increase the count of movies by production company, the pass rate stabilizes around 40-50%'\n",
    "* Romance, Horror, and Music are the most likely to pass the test in our data set, though these all have very different movie counts.\n",
    "* Much of our data set passes one or more criterion, but most do not pass all 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fdbe280",
   "metadata": {},
   "source": [
    "# Text Analysis\n",
    "The purpose of this section is to gather information on the text frequencies and predictive power based on movie titles and overviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a44b99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4873154c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"bechdel_analysis_data_cleaned.csv\", float_precision=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3fbcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "overviews_bag = vectorizer.fit_transform(data[\"overview\"])\n",
    "titles_bag = vectorizer.fit_transform(data[\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c8fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8d9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(overviews_bag.toarray())\n",
    "overviews_bag.toarray()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1be265",
   "metadata": {},
   "source": [
    "#### Prediction Using Bag of Words on Movie Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1d0d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = overviews_bag.toarray()\n",
    "y = data[\"binary_PASS\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "lr = LogisticRegression(C=100.0, random_state=1, solver='lbfgs', multi_class='ovr', max_iter=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b492ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1ee673",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50770990",
   "metadata": {},
   "source": [
    "#### Prediction TF-IDF on Movie Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3db966e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(data[\"overview\"])\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head())\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244bc9aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfIdf.toarray()\n",
    "y = data[\"binary_PASS\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "lr = LogisticRegression(C=100.0, random_state=1, solver='lbfgs', multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae2f594",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b66d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d66aae9",
   "metadata": {},
   "source": [
    "#### Prediction Using Bag of Words on Movie Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a301d538",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titles_bag.toarray()\n",
    "y = data[\"binary_PASS\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "lr = LogisticRegression(C=100.0, random_state=1, solver='lbfgs', multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b387ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9aa0c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8827f73",
   "metadata": {},
   "source": [
    "#### Prediction Using TF-IDF on Movie Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77575645",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfIdfVectorizer=TfidfVectorizer(use_idf=True)\n",
    "tfIdf = tfIdfVectorizer.fit_transform(data[\"title\"])\n",
    "df = pd.DataFrame(tfIdf[0].T.todense(), index=tfIdfVectorizer.get_feature_names_out(), columns=[\"TF-IDF\"])\n",
    "df = df.sort_values('TF-IDF', ascending=False)\n",
    "print (df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c71cf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tfIdf.toarray()\n",
    "y = data[\"binary_PASS\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "lr = LogisticRegression(C=100.0, random_state=1, solver='lbfgs', multi_class='ovr', max_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d758dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a826f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3bf96f",
   "metadata": {},
   "source": [
    "#### Misra Gries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfe7d785",
   "metadata": {},
   "outputs": [],
   "source": [
    "def misra_gries(token, token_dict, k):\n",
    "    if token in token_dict:\n",
    "        token_dict[token] += 1\n",
    "    elif len(token_dict) < k - 1:\n",
    "        token_dict[token] = 1\n",
    "    else:\n",
    "        for token in token_dict.copy():\n",
    "            token_dict[token] -= 1\n",
    "            if token_dict[token] == 0:\n",
    "                token_dict.pop(token)\n",
    "    return token_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebc2e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_false_pos(file_name, k, freqs):\n",
    "    fp = open(file_name, 'r')\n",
    "    false_pos = []\n",
    "    token_dict = {}\n",
    "    token_count = 0\n",
    "    while True:\n",
    "        token = fp.readline().strip()\n",
    "        if not token:\n",
    "            break\n",
    "        token_count += 1\n",
    "        if token in token_dict:\n",
    "            token_dict[token] += 1\n",
    "        else:\n",
    "            token_dict[token] = 1\n",
    "    for token in freqs:\n",
    "        if token_dict[token] <= (token_count/k):\n",
    "            false_pos.append(token)\n",
    "    fp.close()\n",
    "    print(\"TOKEN COUNT\", token_count)\n",
    "    print(\"Proportion of false positives:\", (len(false_pos)/len(freqs)))\n",
    "    return false_pos       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249bdfd7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "titles_tokenized = data_pass.title.str.split()\n",
    "overviews_tokenized = data_pass.overview.str.split()\n",
    "\n",
    "with open('passing_title_tokens.txt', 'w') as f:    \n",
    "    for row in titles_tokenized:\n",
    "        for word in row:\n",
    "            try:\n",
    "                f.write(word)\n",
    "                f.write('\\n')\n",
    "            except:\n",
    "                continue\n",
    "f.close()\n",
    "\n",
    "with open('passing_overview_tokens.txt', 'w') as f:    \n",
    "    for row in overviews_tokenized:\n",
    "        for word in row:\n",
    "            try:\n",
    "                f.write(word)\n",
    "                f.write('\\n')\n",
    "            except:\n",
    "                continue\n",
    "f.close()\n",
    "\n",
    "fail_data = data[data[\"binary_PASS\"] == 0]\n",
    "titles_tokenized = fail_data.title.str.split()\n",
    "overviews_tokenized = fail_data.overview.str.split()\n",
    "\n",
    "with open('failing_title_tokens.txt', 'w') as f:    \n",
    "    for row in titles_tokenized:\n",
    "        for word in row:\n",
    "            try:\n",
    "                f.write(word)\n",
    "                f.write('\\n')\n",
    "            except:\n",
    "                continue\n",
    "f.close()\n",
    "\n",
    "with open('failing_overview_tokens.txt', 'w') as f:    \n",
    "    for row in overviews_tokenized:\n",
    "        for word in row:\n",
    "            try:\n",
    "                f.write(word)\n",
    "                f.write('\\n')\n",
    "            except:\n",
    "                continue\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82fc652e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(file_name, k=10):\n",
    "    fp = open(file_name, 'r')\n",
    "    token_dict = {}\n",
    "    token_count = 0\n",
    "    while True:\n",
    "        token = fp.readline().strip()\n",
    "        if not token:\n",
    "            print(\"End of the stream, m =\", token_count)\n",
    "            fp.close()\n",
    "            return token_dict\n",
    "        token_dict = misra_gries(token, token_dict, k)\n",
    "        token_count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23409b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pt_freqs = run('passing_title_tokens.txt', 500)\n",
    "print(pt_freqs)\n",
    "print()\n",
    "print(\"False positives:\", calc_false_pos('passing_title_tokens.txt', 15, pt_freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a2c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "po_freqs = run('passing_overview_tokens.txt', 1000)\n",
    "print(po_freqs)\n",
    "print()\n",
    "print(\"False positives:\", calc_false_pos('passing_overview_tokens.txt', 15, po_freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ab7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_freqs = run('failing_title_tokens.txt', 250)\n",
    "print(ft_freqs)\n",
    "print()\n",
    "print(\"False positives:\", calc_false_pos('failing_title_tokens.txt', 15, ft_freqs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "090e4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fo_freqs = run('failing_overview_tokens.txt', 1500)\n",
    "print(fo_freqs)\n",
    "print()\n",
    "print(\"False positives:\", calc_false_pos('failing_overview_tokens.txt', 15, fo_freqs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3067bf3",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "- The movie overview was a much better predictor for passing the bechdel test, likely because the overview simply contains more data. Each summary has multiple sentences of data, as opposed to just a few words for the title.\n",
    "- The TF-IDF approach worked slightly better than the bag of words. \n",
    "- Stop words make misra gries difficult, but make for better prediction metrics.\n",
    "- Misra Gries was ineffective for this data set as there aren't many frequent words besides stop words."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8acdda",
   "metadata": {},
   "source": [
    "# Predictive Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa8f1664",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing, tree, neighbors, linear_model, ensemble, naive_bayes, svm, neural_network\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, f1_score, roc_curve, auc, mean_squared_error, accuracy_score\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0558e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"bechdel_analysis_data_cleaned_with_genres.csv\", float_precision=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde29f60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prod_comp_data = data.prod_comps\n",
    "overview_data = data.overview\n",
    "\n",
    "data = data.drop(['prod_comps', 'overview', 'title', 'imdb'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bf4f90",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y = data.binary_PASS\n",
    "data = data.drop(['binary_PASS', 'clean_test'], axis=1)\n",
    "X = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7835a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abc5b33",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82004d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_accuracy = {1: None, 5: None, 10: None, 50: None, 100: None}\n",
    "for i in dt_accuracy:\n",
    "    # Train decision tree classifier with given max_depth\n",
    "    dt_clf = tree.DecisionTreeClassifier(max_depth=i)\n",
    "    dt_accuracy[i] = cross_val_score(dt_clf, X, Y, cv=5).mean()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec7a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-nearest Neighbors\n",
    "knn_accuracy = {1: None, 2: None, 3: None, 4: None, 5: None, 10: None, 15: None}\n",
    "for i in knn_accuracy:\n",
    "    # Train k-nearest neigbor classifier with given n_neighbors\n",
    "    knn_clf = neighbors.KNeighborsClassifier(n_neighbors=i)\n",
    "    knn_accuracy[i] = cross_val_score(knn_clf, X, Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1024638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "lr_accuracy = {0.001: None, 0.01: None, 0.1: None, 0.5: None, 1: None}\n",
    "for i in lr_accuracy:\n",
    "    # Train logistic regression classifier with given C\n",
    "    lr_clf = linear_model.LogisticRegression(C=i)\n",
    "    lr_accuracy[i] = cross_val_score(lr_clf, X, Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea7c9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb_accuracy = {0.001: None, 0.01: None, 0.1: None, 0.5: None, 1: None}\n",
    "for i in nb_accuracy:\n",
    "    # Train naive bayes classifier with given alpha\n",
    "    nb_clf = naive_bayes.ComplementNB(alpha=i)\n",
    "    nb_accuracy[i] = cross_val_score(nb_clf, X, Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994438d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "sv_accuracy = {0.001: None, 0.01: None, 0.1: None, 0.5: None, 1: None}\n",
    "for i in sv_accuracy:\n",
    "    # Train support vector classifier with given C\n",
    "    sv_clf = svm.SVC(C=i)\n",
    "    sv_accuracy[i] = cross_val_score(sv_clf, X, Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ff21ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron Classifier (NN)\n",
    "mlp_accuracy = {10: None, 25: None, 50: None, 75: None, 100: None}\n",
    "for i in mlp_accuracy:\n",
    "    # Train multilayer perceptron classifier with given \n",
    "    mlp_clf = neural_network.MLPClassifier(hidden_layer_sizes=(i,))\n",
    "    mlp_accuracy[i] = cross_val_score(mlp_clf, X, Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa74253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf_accuracy = {10: None, 25: None, 50: None, 100: None, 150: None}\n",
    "for i in rf_accuracy:\n",
    "    # Train random forest classifier with given n_estimators\n",
    "    rf_clf = ensemble.RandomForestClassifier(n_estimators=i)\n",
    "    rf_accuracy[i] = cross_val_score(rf_clf, X, Y, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c542012b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.title(\"Hyperparameter Accuracy for Decision Tree Classifier\")\n",
    "plt.plot()\n",
    "x = [i for i in dt_accuracy.keys()]\n",
    "y = [i for i in dt_accuracy.values()]\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xticks(x)\n",
    "plt.ylabel(\"Five-fold Cross-Validation Accuracy\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Hyperparameter Accuracy for K-Nearest Neighbors Classifier\")\n",
    "x = [i for i in knn_accuracy.keys()]\n",
    "y = [i for i in knn_accuracy.values()]\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xticks(x)\n",
    "plt.ylabel(\"Five-fold Cross-Validation Accuracy\")\n",
    "plt.xlabel(\"n_neighbors\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Hyperparameter Accuracy for Logistic Regression\")\n",
    "x = [i for i in lr_accuracy.keys()]\n",
    "y = [i for i in lr_accuracy.values()]\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xticks(x, rotation=45)\n",
    "plt.ylabel(\"Five-fold Cross-Validation Accuracy\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Hyperparameter Accuracy for Naive Bayes\")\n",
    "x = [i for i in nb_accuracy.keys()]\n",
    "y = [i for i in nb_accuracy.values()]\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xticks(x, rotation=45)\n",
    "plt.ylabel(\"Five-fold Cross-Validation Accuracy\")\n",
    "plt.xlabel(\"alpha\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Hyperparameter Accuracy for Support Vector Classifier\")\n",
    "plt.plot()\n",
    "x = [i for i in sv_accuracy.keys()]\n",
    "y = [i for i in sv_accuracy.values()]\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xticks(x)\n",
    "plt.ylabel(\"Five-fold Cross-Validation Accuracy\")\n",
    "plt.xlabel(\"C\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Hyperparameter Accuracy for Multilayer Perceptron Classifier\")\n",
    "plt.plot()\n",
    "x = [i for i in mlp_accuracy.keys()]\n",
    "y = [i for i in mlp_accuracy.values()]\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xticks(x)\n",
    "plt.ylabel(\"Five-fold Cross-Validation Accuracy\")\n",
    "plt.xlabel(\"hidden_layer_sizes\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Hyperparameter Accuracy for Random Forest Classifier\")\n",
    "plt.plot()\n",
    "x = [i for i in rf_accuracy.keys()]\n",
    "y = [i for i in rf_accuracy.values()]\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xticks(x)\n",
    "plt.ylabel(\"Five-fold Cross-Validation Accuracy\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c390793",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_clf = tree.DecisionTreeClassifier(max_depth=1)\n",
    "dt_clf.fit(X, Y)\n",
    "tree.plot_tree(dt_clf, feature_names=[i for i in X.columns], class_names='binary_PASS',filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d0073e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
    "\n",
    "# Train DT\n",
    "dt_clf = tree.DecisionTreeClassifier(max_depth=1)\n",
    "dt_clf.fit(x_train, y_train)\n",
    "dt_pred = dt_clf.predict(x_test)\n",
    "\n",
    "# Train KNN\n",
    "knn_clf = neighbors.KNeighborsClassifier(n_neighbors=10)\n",
    "knn_clf.fit(x_train, y_train)\n",
    "knn_pred = knn_clf.predict(x_test)\n",
    "\n",
    "# Train LR\n",
    "lr_clf = linear_model.LogisticRegression(C=0.5)\n",
    "lr_clf.fit(x_train, y_train)\n",
    "lr_pred = lr_clf.predict(x_test)\n",
    "\n",
    "# Train NB\n",
    "nb_clf = naive_bayes.ComplementNB(alpha=0.5)\n",
    "nb_clf.fit(x_train, y_train)\n",
    "nb_pred = nb_clf.predict(x_test)\n",
    "\n",
    "# Train SVC\n",
    "sv_clf = svm.SVC(C=0.5, probability=True)\n",
    "sv_clf.fit(x_train, y_train)\n",
    "sv_pred = sv_clf.predict(x_test)\n",
    "\n",
    "# Train MLP\n",
    "mlp_clf = neural_network.MLPClassifier(hidden_layer_sizes=(50,))\n",
    "mlp_clf.fit(x_train, y_train)\n",
    "mlp_pred = mlp_clf.predict(x_test)\n",
    "\n",
    "# Train RF\n",
    "rf_clf = ensemble.RandomForestClassifier(n_estimators=10)\n",
    "rf_clf.fit(x_train, y_train)\n",
    "rf_pred = rf_clf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce05b96",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Calculate confusion matrix\n",
    "dt_conf_mat = confusion_matrix(y_test, dt_pred)\n",
    "dt_f1 = f1_score(y_test, dt_pred)\n",
    "\n",
    "knn_conf_mat = confusion_matrix(y_test, knn_pred)\n",
    "knn_f1 = f1_score(y_test, knn_pred)\n",
    "\n",
    "lr_conf_mat = confusion_matrix(y_test, lr_pred)\n",
    "lr_f1 = f1_score(y_test, lr_pred)\n",
    "\n",
    "nb_conf_mat = confusion_matrix(y_test, nb_pred)\n",
    "nb_f1 = f1_score(y_test, nb_pred)\n",
    "\n",
    "sv_conf_mat = confusion_matrix(y_test, sv_pred)\n",
    "sv_f1 = f1_score(y_test, sv_pred)\n",
    "\n",
    "mlp_conf_mat = confusion_matrix(y_test, mlp_pred)\n",
    "mlp_f1 = f1_score(y_test, mlp_pred)\n",
    "\n",
    "rf_conf_mat = confusion_matrix(y_test, rf_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "\n",
    "# Print output\n",
    "print(\"Decision Tree Confusion Matrix\")\n",
    "print(dt_conf_mat)\n",
    "print(\"K-Nearest Neighbor Confusion Matrix\")\n",
    "print(knn_conf_mat)\n",
    "print(\"Logistic Regression Confusion Matrix\")\n",
    "print(lr_conf_mat)\n",
    "print(\"Naive Bayes Confusion Matrix\")\n",
    "print(nb_conf_mat)\n",
    "print(\"SVC Confusion Matrix\")\n",
    "print(sv_conf_mat)\n",
    "print(\"Multilayer Perceptron Confusion Matrix\")\n",
    "print(mlp_conf_mat)\n",
    "print(\"Random Forest Confusion Matrix\")\n",
    "print(rf_conf_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e7990e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision, recall for Decision Tree\n",
    "dt_p = (dt_conf_mat[0][0]/(dt_conf_mat[0][0] + dt_conf_mat[1][0]))\n",
    "dt_r = (dt_conf_mat[0][0]/(dt_conf_mat[0][0] + dt_conf_mat[0][1]))\n",
    "\n",
    "# Precision, recall for K-Nearest Neighbor\n",
    "knn_p = (knn_conf_mat[0][0]/(knn_conf_mat[0][0] + knn_conf_mat[1][0]))\n",
    "knn_r = (knn_conf_mat[0][0]/(knn_conf_mat[0][0] + knn_conf_mat[0][1]))\n",
    "\n",
    "# Precision, recall for Logistic Regression\n",
    "lr_p = (lr_conf_mat[0][0]/(lr_conf_mat[0][0] + lr_conf_mat[1][0]))\n",
    "lr_r = (lr_conf_mat[0][0]/(lr_conf_mat[0][0] + lr_conf_mat[0][1]))\n",
    "\n",
    "# Precision, recall for Naive Bayes\n",
    "nb_p = (nb_conf_mat[0][0]/(nb_conf_mat[0][0] + nb_conf_mat[1][0]))\n",
    "nb_r = (nb_conf_mat[0][0]/(nb_conf_mat[0][0] + nb_conf_mat[0][1]))\n",
    "\n",
    "# Precision, recall for Support Vector Machine\n",
    "sv_p = (sv_conf_mat[0][0]/(sv_conf_mat[0][0] + sv_conf_mat[1][0]))\n",
    "sv_r = (sv_conf_mat[0][0]/(sv_conf_mat[0][0] + sv_conf_mat[0][1]))\n",
    "\n",
    "# Precision, recall for Multilayer Perceptron\n",
    "mlp_p = (mlp_conf_mat[0][0]/(mlp_conf_mat[0][0] + mlp_conf_mat[1][0]))\n",
    "mlp_r = (mlp_conf_mat[0][0]/(mlp_conf_mat[0][0] + mlp_conf_mat[0][1]))\n",
    "\n",
    "# Precision, recall for Random Forest Classifier\n",
    "rf_p = (rf_conf_mat[0][0]/(rf_conf_mat[0][0] + rf_conf_mat[1][0]))\n",
    "rf_r = (rf_conf_mat[0][0]/(rf_conf_mat[0][0] + rf_conf_mat[0][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6494dedd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate output\n",
    "classifiers = ['DT', 'KNN', 'LR', 'NB', 'SVC', 'MLP', 'RF']\n",
    "precisions = [dt_p, knn_p, lr_p, nb_r, sv_r, mlp_r, rf_r]\n",
    "recalls = [dt_r, knn_r, lr_r, nb_p, sv_p, mlp_p, rf_p]\n",
    "f1s = [dt_f1, knn_f1, lr_f1, nb_f1, sv_f1, mlp_f1, rf_f1]\n",
    "x_axis= np.arange(len(classifiers))\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(x_axis-0.2, precisions, width=0.2, label=\"Precision\")\n",
    "plt.bar(x_axis, recalls, width=0.2, label=\"Recall\")\n",
    "plt.bar(x_axis+0.2, f1s, width=0.2, label=\"F1\")\n",
    "\n",
    "plt.xticks(x_axis, classifiers)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81293e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DT Stats\n",
    "dt_prob = dt_clf.predict_proba(x_test)\n",
    "dt_labels = (y_test == 1)\n",
    "\n",
    "dt_fpr, dt_tpr, dt_thresh = roc_curve(dt_labels, dt_prob[:,1])\n",
    "dt_roc_auc = auc(dt_fpr, dt_tpr)\n",
    "dt_legend = \"DT (AUC = %0.4f)\" % dt_roc_auc\n",
    "\n",
    "# KNN Stats\n",
    "knn_prob = knn_clf.predict_proba(x_test)\n",
    "knn_labels = (y_test == 1)\n",
    "\n",
    "knn_fpr, knn_tpr, knn_thresh = roc_curve(knn_labels, knn_prob[:,1])\n",
    "knn_roc_auc = auc(knn_fpr, knn_tpr)\n",
    "knn_legend = \"KNN (AUC = %0.4f)\" % knn_roc_auc\n",
    "\n",
    "# LR Stats\n",
    "lr_prob = lr_clf.predict_proba(x_test)\n",
    "lr_labels = (y_test == 1)\n",
    "\n",
    "lr_fpr, lr_tpr, lr_thresh = roc_curve(lr_labels, lr_prob[:,1])\n",
    "lr_roc_auc = auc(lr_fpr, lr_tpr)\n",
    "lr_legend = \"LR (AUC = %0.4f)\" % lr_roc_auc\n",
    "\n",
    "# NB Stats\n",
    "nb_prob = nb_clf.predict_proba(x_test)\n",
    "nb_labels = (y_test == 1)\n",
    "\n",
    "nb_fpr, nb_tpr, nb_thresh = roc_curve(nb_labels, nb_prob[:,1])\n",
    "nb_roc_auc = auc(nb_fpr, nb_tpr)\n",
    "nb_legend = \"NB (AUC = %0.4f)\" % nb_roc_auc\n",
    "\n",
    "# SVC Stats\n",
    "sv_prob = sv_clf.predict_proba(x_test)\n",
    "sv_labels = (y_test == 1)\n",
    "\n",
    "sv_fpr, sv_tpr, sv_thresh = roc_curve(sv_labels, sv_prob[:,1])\n",
    "sv_roc_auc = auc(sv_fpr, sv_tpr)\n",
    "sv_legend = \"SV (AUC = %0.4f)\" % sv_roc_auc\n",
    "\n",
    "# MLP Stats\n",
    "mlp_prob = mlp_clf.predict_proba(x_test)\n",
    "mlp_labels = (y_test == 1)\n",
    "\n",
    "mlp_fpr, mlp_tpr, mlp_thresh = roc_curve(mlp_labels, mlp_prob[:,1])\n",
    "mlp_roc_auc = auc(mlp_fpr, mlp_tpr)\n",
    "mlp_legend = \"MLP (AUC = %0.4f)\" % mlp_roc_auc\n",
    "\n",
    "# SVC Stats\n",
    "rf_prob = rf_clf.predict_proba(x_test)\n",
    "rf_labels = (y_test == 1)\n",
    "\n",
    "rf_fpr, rf_tpr, rf_thresh = roc_curve(rf_labels, rf_prob[:,1])\n",
    "rf_roc_auc = auc(rf_fpr, rf_tpr)\n",
    "rf_legend = \"RF (AUC = %0.4f)\" % rf_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e086303",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make AUC plot\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(dt_fpr, dt_tpr, label=dt_legend)\n",
    "plt.plot(knn_fpr, knn_tpr, label=knn_legend)\n",
    "plt.plot(lr_fpr, lr_tpr, label=lr_legend)\n",
    "plt.plot(nb_fpr, nb_tpr, label=nb_legend)\n",
    "plt.plot(sv_fpr, sv_tpr, label=sv_legend)\n",
    "plt.plot(mlp_fpr, mlp_tpr, label=mlp_legend)\n",
    "plt.plot(rf_fpr, rf_tpr, label=rf_legend)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f72f650",
   "metadata": {},
   "source": [
    "## Interesting Observations\n",
    "The models are all around the level of a random guess at this point. Logistic Regression is the best here, but not by much. From here, we revisted from preprocessing and only got slightly better results. We next try a grid search to help tune hyperparameters."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3346d640",
   "metadata": {},
   "source": [
    "## Brute Force - GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb756b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "dt_params = {'criterion': ['gini', 'entropy'],'splitter': ['best', 'random'], 'max_depth': [None, 1, 5, 10, 50], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 5, 10]}\n",
    "\n",
    "dt = tree.DecisionTreeClassifier()\n",
    "\n",
    "dt_grid_search = GridSearchCV(estimator=dt, param_grid=dt_params, cv=5, n_jobs=-1,\n",
    "                          verbose=1, scoring='accuracy')\n",
    "\n",
    "dt_grid_search.fit(X, Y)\n",
    "\n",
    "dt_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d692e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Nearest Neighbors\n",
    "knn_params = {'n_neighbors': [1, 3, 5, 10, 50], \n",
    "              'weights': ['uniform', 'distance'], \n",
    "              'algorithm': ['ball_tree', 'kd_tree', 'brute'], \n",
    "              'leaf_size': [5, 10, 30, 50]}\n",
    "\n",
    "knn = neighbors.KNeighborsClassifier()\n",
    "\n",
    "knn_grid_search = GridSearchCV(estimator=knn, param_grid=knn_params, cv=5, n_jobs=-1,\n",
    "                          verbose=1, scoring='accuracy')\n",
    "\n",
    "knn_grid_search.fit(X, Y)\n",
    "\n",
    "knn_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87f42489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logisitic Regression\n",
    "lr_params = {'C': [0.001, 0.01, 0.1, 0.5, 1], \n",
    "              'solver': ['liblinear', 'lbfgs', 'newton-cholesky'], \n",
    "              'penalty': ['l1', 'l2', 'elasticnet', None]}\n",
    "\n",
    "lr = linear_model.LogisticRegression()\n",
    "\n",
    "lr_grid_search = GridSearchCV(estimator=lr, param_grid=lr_params, cv=5, n_jobs=-1,\n",
    "                          verbose=1, scoring='accuracy')\n",
    "\n",
    "lr_grid_search.fit(X, Y)\n",
    "\n",
    "lr_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d2687c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "nb_params = {'alpha': [0.0001, 0.001, 0.01, 0.1, 0.5, 1, 1.5], \n",
    "              'norm': [True, False]}\n",
    "\n",
    "\n",
    "nb = naive_bayes.ComplementNB()\n",
    "\n",
    "nb_grid_search = GridSearchCV(estimator=nb, param_grid=nb_params, cv=5, n_jobs=-1,\n",
    "                          verbose=1, scoring='accuracy')\n",
    "\n",
    "nb_grid_search.fit(X, Y)\n",
    "\n",
    "nb_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902ec211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out for convenience as the search takes significantly longer than other models\n",
    "# Support Vector Machine\n",
    "# sv_params = {'C': [0.001, 0.01, 0.1, 0.5, 1], \n",
    "#               'kernel': ['linear', 'poly', 'rbf']}\n",
    "# # , \n",
    "# #               'gamma': ['scale', 'auto']}\n",
    "\n",
    "\n",
    "# sv = svm.SVC(probability=True)\n",
    "\n",
    "# sv_grid_search = GridSearchCV(estimator=sv, param_grid=sv_params, cv=5, n_jobs=-1,\n",
    "#                           verbose=1, scoring='accuracy')\n",
    "\n",
    "# sv_grid_search.fit(X, Y)\n",
    "\n",
    "# sv_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc54983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multilayer Perceptron\n",
    "mlp_params = {'hidden_layer_sizes': [(10,), (25,), (50,), (100,)],\n",
    "              'activation': ['logistic', 'relu', 'identity'],\n",
    "              'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "              'learning_rate': ['constant', 'adaptive'],\n",
    "              'alpha': [0.0001, 0.001, 0.01]}\n",
    "\n",
    "mlp = neural_network.MLPClassifier()\n",
    "\n",
    "mlp_grid_search = GridSearchCV(estimator=mlp, param_grid=mlp_params, cv=5, n_jobs=-1,\n",
    "                          verbose=1, scoring='accuracy')\n",
    "\n",
    "mlp_grid_search.fit(X, Y)\n",
    "\n",
    "mlp_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9250b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "params = {'n_estimators': [10, 25, 50, 100], \n",
    "          'criterion': ['gini', 'entropy'],\n",
    "          'max_depth': [None, 1, 5, 10, 50],\n",
    "          'min_samples_split': [2, 5, 10],\n",
    "          'min_samples_leaf': [1, 5, 10]}\n",
    "\n",
    "rf = ensemble.RandomForestClassifier()\n",
    "\n",
    "rf_grid_search = GridSearchCV(estimator=rf, param_grid=params, cv=5, n_jobs=-1,\n",
    "                          verbose=1, scoring='accuracy')\n",
    "\n",
    "rf_grid_search.fit(X, Y)\n",
    "\n",
    "rf_grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd8505a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "# Predict labels\n",
    "dt_best = dt_grid_search.best_estimator_\n",
    "dt_pred = dt_best.predict(x_test)\n",
    "\n",
    "# Confusion matrix and F1 score\n",
    "dt_conf_mat = confusion_matrix(y_test, dt_pred)\n",
    "dt_f1 = f1_score(y_test, dt_pred)\n",
    "\n",
    "# Precision and recall\n",
    "dt_p = (dt_conf_mat[0][0]/(dt_conf_mat[0][0] + dt_conf_mat[1][0]))\n",
    "dt_r = (dt_conf_mat[0][0]/(dt_conf_mat[0][0] + dt_conf_mat[0][1]))\n",
    "\n",
    "# DT stats\n",
    "dt_prob = dt_best.predict_proba(x_test)\n",
    "dt_labels = (y_test == 1)\n",
    "\n",
    "dt_fpr, dt_tpr, dt_thresh = roc_curve(dt_labels, dt_prob[:,1])\n",
    "dt_roc_auc = auc(dt_fpr, dt_tpr)\n",
    "dt_legend = \"DT (AUC = %0.4f)\" % dt_roc_auc\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "# Predict labels\n",
    "knn_best = knn_grid_search.best_estimator_\n",
    "knn_pred = knn_best.predict(x_test)\n",
    "\n",
    "# Confusion matrix and F1 score\n",
    "knn_conf_mat = confusion_matrix(y_test, knn_pred)\n",
    "knn_f1 = f1_score(y_test, knn_pred)\n",
    "\n",
    "# Precision and recall\n",
    "knn_p = (knn_conf_mat[0][0]/(knn_conf_mat[0][0] + knn_conf_mat[1][0]))\n",
    "knn_r = (knn_conf_mat[0][0]/(knn_conf_mat[0][0] + knn_conf_mat[0][1]))\n",
    "\n",
    "# KNN stats\n",
    "knn_prob = knn_best.predict_proba(x_test)\n",
    "knn_labels = (y_test == 1)\n",
    "\n",
    "knn_fpr, knn_tpr, knn_thresh = roc_curve(knn_labels, knn_prob[:,1])\n",
    "knn_roc_auc = auc(knn_fpr, knn_tpr)\n",
    "knn_legend = \"KNN (AUC = %0.4f)\" % knn_roc_auc\n",
    "\n",
    "# Logistic Regression\n",
    "# Predict labels\n",
    "lr_best = lr_grid_search.best_estimator_\n",
    "lr_pred = lr_best.predict(x_test)\n",
    "\n",
    "# Confusion matrix and F1 score\n",
    "lr_conf_mat = confusion_matrix(y_test, lr_pred)\n",
    "lr_f1 = f1_score(y_test, lr_pred)\n",
    "\n",
    "# Precision and recall\n",
    "lr_p = (lr_conf_mat[0][0]/(lr_conf_mat[0][0] + lr_conf_mat[1][0]))\n",
    "lr_r = (lr_conf_mat[0][0]/(lr_conf_mat[0][0] + lr_conf_mat[0][1]))\n",
    "\n",
    "# LR stats\n",
    "lr_prob = lr_best.predict_proba(x_test)\n",
    "lr_labels = (y_test == 1)\n",
    "\n",
    "lr_fpr, lr_tpr, lr_thresh = roc_curve(lr_labels, lr_prob[:,1])\n",
    "lr_roc_auc = auc(lr_fpr, lr_tpr)\n",
    "lr_legend = \"LR (AUC = %0.4f)\" % lr_roc_auc\n",
    "\n",
    "# Naive Bayes\n",
    "# Predict labels\n",
    "nb_best = nb_grid_search.best_estimator_\n",
    "nb_pred = nb_best.predict(x_test)\n",
    "\n",
    "# Confusion matrix and F1 score\n",
    "nb_conf_mat = confusion_matrix(y_test, nb_pred)\n",
    "nb_f1 = f1_score(y_test, nb_pred)\n",
    "\n",
    "# Precision and recall\n",
    "nb_p = (nb_conf_mat[0][0]/(nb_conf_mat[0][0] + nb_conf_mat[1][0]))\n",
    "nb_r = (nb_conf_mat[0][0]/(nb_conf_mat[0][0] + nb_conf_mat[0][1]))\n",
    "\n",
    "# NB stats\n",
    "nb_prob = nb_best.predict_proba(x_test)\n",
    "nb_labels = (y_test == 1)\n",
    "\n",
    "nb_fpr, nb_tpr, nb_thresh = roc_curve(nb_labels, nb_prob[:,1])\n",
    "nb_roc_auc = auc(nb_fpr, nb_tpr)\n",
    "nb_legend = \"NB (AUC = %0.4f)\" % nb_roc_auc\n",
    "\n",
    "# Multilayer Perceptron\n",
    "# Predict labels\n",
    "mlp_best = mlp_grid_search.best_estimator_\n",
    "mlp_pred = mlp_best.predict(x_test)\n",
    "\n",
    "# Confusion matrix and F1 score\n",
    "mlp_conf_mat = confusion_matrix(y_test, mlp_pred)\n",
    "mlp_f1 = f1_score(y_test, mlp_pred)\n",
    "\n",
    "# Precision and recall\n",
    "mlp_p = (mlp_conf_mat[0][0]/(mlp_conf_mat[0][0] + mlp_conf_mat[1][0]))\n",
    "mlp_r = (mlp_conf_mat[0][0]/(mlp_conf_mat[0][0] + mlp_conf_mat[0][1]))\n",
    "\n",
    "# MLP stats\n",
    "mlp_prob = mlp_best.predict_proba(x_test)\n",
    "mlp_labels = (y_test == 1)\n",
    "\n",
    "mlp_fpr, mlp_tpr, mlp_thresh = roc_curve(mlp_labels, mlp_prob[:,1])\n",
    "mlp_roc_auc = auc(mlp_fpr, mlp_tpr)\n",
    "mlp_legend = \"MLP (AUC = %0.4f)\" % mlp_roc_auc\n",
    "\n",
    "# Random Forest\n",
    "# Predict labels\n",
    "rf_best = rf_grid_search.best_estimator_\n",
    "rf_pred = rf_best.predict(x_test)\n",
    "\n",
    "# Confusion matrix and F1 score\n",
    "rf_conf_mat = confusion_matrix(y_test, rf_pred)\n",
    "rf_f1 = f1_score(y_test, rf_pred)\n",
    "\n",
    "# Precision and recall\n",
    "rf_p = (rf_conf_mat[0][0]/(rf_conf_mat[0][0] + rf_conf_mat[1][0]))\n",
    "rf_r = (rf_conf_mat[0][0]/(rf_conf_mat[0][0] + rf_conf_mat[0][1]))\n",
    "\n",
    "# RF stats\n",
    "rf_prob = rf_best.predict_proba(x_test)\n",
    "rf_labels = (y_test == 1)\n",
    "\n",
    "rf_fpr, rf_tpr, rf_thresh = roc_curve(rf_labels, rf_prob[:,1])\n",
    "rf_roc_auc = auc(rf_fpr, rf_tpr)\n",
    "rf_legend = \"RF (AUC = %0.4f)\" % rf_roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb20459",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized DT\n",
    "tree.plot_tree(dt_best, feature_names=[i for i in X.columns], class_names='binary_PASS',filled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f8d482",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Generate output\n",
    "classifiers = ['DT', 'KNN', 'LR', 'NB', 'MLP', 'RF']\n",
    "precisions = [dt_p, knn_p, lr_p, nb_r, mlp_r, rf_r]\n",
    "recalls = [dt_r, knn_r, lr_r, nb_p, mlp_p, rf_p]\n",
    "f1s = [dt_f1, knn_f1, lr_f1, nb_f1, mlp_f1, rf_f1]\n",
    "x_axis= np.arange(len(classifiers))\n",
    "\n",
    "plt.figure()\n",
    "plt.bar(x_axis-0.2, precisions, width=0.2, label=\"Precision\")\n",
    "plt.bar(x_axis, recalls, width=0.2, label=\"Recall\")\n",
    "plt.bar(x_axis+0.2, f1s, width=0.2, label=\"F1\")\n",
    "\n",
    "plt.xticks(x_axis, classifiers)\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20381c7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Make AUC plot\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(dt_fpr, dt_tpr, label=dt_legend)\n",
    "plt.plot(knn_fpr, knn_tpr, label=knn_legend)\n",
    "plt.plot(lr_fpr, lr_tpr, label=lr_legend)\n",
    "plt.plot(nb_fpr, nb_tpr, label=nb_legend)\n",
    "# plt.plot(sv_fpr, sv_tpr, label=sv_legend)\n",
    "plt.plot(mlp_fpr, mlp_tpr, label=mlp_legend)\n",
    "plt.plot(rf_fpr, rf_tpr, label=rf_legend)\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9680b1b6",
   "metadata": {},
   "source": [
    "### Observations\n",
    "The grid search improved most models at least a fair amount. The Random Forest was the best, with K-Nearest Neighbors and Logistic Regression not far behind."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
